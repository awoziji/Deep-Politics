{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish Socialist vs. People's Parties Affinity Classification\n",
    "\n",
    "## VGG16 Fine Tuning\n",
    "\n",
    "In the previous notebook ([TransferLearning.ipynb](TransferLearning.ipynb)) I tested the VGG16 transfer learning by training only the last FC layer. All the other convolutions blocks had the weights from the pre-trained VGG16.\n",
    "\n",
    "This notebook, I will try to apply a fine tuning: to train 1 or 2 convolutional blocks + FC layer. The FC layer will use initial weights from the best model obtained in the previous step (Transfer Learning notebook). See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "Let's load some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import time, os\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from __future__ import with_statement\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of paths for dataset, previous trained weights for the FC layer, earlystopping model, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save the models\n",
    "modelFolder = 'saved_models'\n",
    "\n",
    "# Path to the file with the weights of the pre-trained VGG16 model\n",
    "weights_path = 'nets/vgg16_weights.h5'\n",
    "\n",
    "# Path to the previous saved top model weights (FC layer trained in Transfer Learning notebook)\n",
    "top_model_weights_path = os.path.join(modelFolder,'transferVGG16_bottleneck_fc_model.h5')\n",
    "\n",
    "# Earlystoping saved model - this name will be modified later by including parameter values\n",
    "earlystoping_path = './saved_models/fineTunning_earlystopnning.h5'\n",
    "\n",
    "# Dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Train & validation folders\n",
    "train_data_dir      = 'data_politics/train'\n",
    "validation_data_dir = 'data_politics/validation'\n",
    "\n",
    "# Train parameters\n",
    "nb_train_samples      = 80 # number of samples for training\n",
    "nb_validation_samples = 20 # number of samples for validation\n",
    "epochs = 10\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the function that will do a fine tuning of the pre-trained VGG16 using FC layer weights trained in the previous notebook:\n",
    "* Load the pre-trained VGG16 as the lower model,\n",
    "* Add the top model as a FC layer,\n",
    "* Load the previous calculated weights for the FC layer,\n",
    "* Freeze a number of layers (a specific number of convolutional blocks): to freeze the last Conv block, freeze 15 layers; to freeze 2 last conv blocks, freeze only 11 layers.\n",
    "* Compilte the computational graph of the model,\n",
    "* Generate training & validation datasets from folders using data augmentation,\n",
    "* Use earlystopping if the validation accuracy is not increasing in 10 iterations,\n",
    "* Save the last best model,\n",
    "* Use SGD optimizer,\n",
    "* Search the best model using different values for the main hyperparameters: epochs, batch size, learning rate, momentum, and the number of layers to freeze.\n",
    "\n",
    "See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "In the first step, I will try one set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunningVGG(epochs, batch_size, learning, mom, freezeLayers):\n",
    "    # Fine tuning function using VGG16 and our weights for the FC layer (top model)\n",
    "    \n",
    "    # Set seeeds for reproductibility\n",
    "    #seed(1)            # numpy seed\n",
    "    #set_random_seed(2) # tensorflow seed\n",
    "    \n",
    "    # Build the VGG16 block using our input size 150, 150, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "    # Build a classifier model to put on top of the convolutional model (FC layer / top model)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Is necessary to start with a fully-trained classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    \n",
    "    # Load the previous calculated weight for the top model\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # Add the model on top of the convolutional base\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # Set the first 'freezeLayers' layers to non-trainable (weights will not be updated)\n",
    "    # This number depends on the blocks to freeze: for the last Conv block freeze 15 layers,\n",
    "    # to freeze 2 last conv blocks freeze only 11 layers.\n",
    "    for layer in model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizers.SGD(lr=learning, momentum=mom), # lr=1e-4, momentum=0.9\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1. / 255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 90)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Generate training and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use earlystopping:\n",
    "    callbacks=[EarlyStopping(\n",
    "                            monitor='val_acc', \n",
    "                            patience=50, # very patient!\n",
    "                            mode='max',\n",
    "                            verbose=1),\n",
    "                ModelCheckpoint(earlystoping_path[:-3]+'_e'+str(epochs)+'b'+str(batch_size)+'l'+str(learning)+'m'+str(mom)+'f'+str(freezeLayers)+'.h5',\n",
    "                            monitor='val_acc', \n",
    "                            save_best_only=True, \n",
    "                            mode='max',\n",
    "                            verbose=0)]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        workers=7, # 7 cores of the CPU!\n",
    "        verbose = 0,\n",
    "        callbacks=callbacks) # remove this param if you dont need early stopping\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training time: %0.1f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "    # Evaluate final test loss and accuracy scores\n",
    "    scoresVal = model.evaluate_generator(validation_generator, nb_validation_samples//batch_size, workers=7)\n",
    "    scoresTr  = model.evaluate_generator(train_generator, nb_train_samples//batch_size, workers=7)\n",
    "    # Print the results\n",
    "    print(freezeLayers, learning, mom, epochs, batch_size, scoresTr[0], scoresVal[0], scoresTr[1], scoresVal[1])\n",
    "\n",
    "    # clean some memory\n",
    "    del base_model\n",
    "    del top_model\n",
    "    del model\n",
    "\n",
    "    del train_datagen\n",
    "    del train_generator\n",
    "    del validation_generator\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Conv block + FC training\n",
    "\n",
    "Let's try the fine tuning for FC and only the last Conv block using `SGD` and earlystopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00057: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0001 0.9 200 2 0.22392664093640632 0.5221619199961424 0.9 0.8\n"
     ]
    }
   ],
   "source": [
    "# FineTunningVGG(epochs, batch_size, learning, mom, freezeLayers)\n",
    "FineTunningVGG(200, 2, 1e-4,  0.9, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after 200 epochs, the model is underfitter (*validation ACC 80%*, *training ACC 90%*). We could decrease the drop rate to reduce the overfitting but we are using the same top model for loading the weights.\n",
    "\n",
    "In the second step, let's try to use different paramters. You should use more values! With this function, you can search for several hyperparamters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00052: early stopping\n",
      "Training time: 0.6 mins ---\n",
      "15 0.0001 0.8 200 2 0.22526256359415128 0.623651000787504 0.875 0.65\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00051: early stopping\n",
      "Training time: 0.5 mins ---\n",
      "15 0.0001 0.8 200 5 0.25028148060664535 0.5772825814783573 0.9500000029802322 0.7000000067055225\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00058: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0001 0.9 200 2 0.1271283920003043 0.6267548841657117 0.9375 0.75\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00078: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0001 0.9 200 5 0.06473202907363884 0.7456640899181366 1.0 0.600000012665987\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00062: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "15 0.0005 0.8 200 2 0.24667534793805998 0.529761411412619 0.925 0.7\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00074: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0005 0.8 200 5 0.1360993977286853 0.7042806297540665 0.9375000037252903 0.6500000134110451\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00078: early stopping\n",
      "Training time: 1.0 mins ---\n",
      "15 0.0005 0.9 200 2 0.15175114670121276 1.011551660700934 0.9375 0.75\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00053: early stopping\n",
      "Training time: 0.5 mins ---\n",
      "15 0.0005 0.9 200 5 0.646004673675634 0.8336098343133926 0.7500000102445483 0.7000000178813934\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00051: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.001 0.8 200 2 0.3981195045402274 0.8767394129186868 0.7625 0.65\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00105: early stopping\n",
      "Training time: 1.0 mins ---\n",
      "15 0.001 0.8 200 5 0.01910734750163101 0.7375606708228588 1.0 0.8500000089406967\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00067: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.001 0.9 200 2 0.589317972958088 0.5364157259464264 0.6875 0.75\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00052: early stopping\n",
      "Training time: 0.5 mins ---\n",
      "15 0.001 0.9 200 5 0.27734723407775164 0.6297195628285408 0.8625000081956387 0.600000012665987\n",
      "Total time: 8.9 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [15] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-4, 5e-4, 1e-3]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [200]\n",
    "batch_sizeValues = [2, 5]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, by trainin the last Conv block and FC layer, you can obtain a `validation accuracy of 85%` in only 1 minute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 2 Conv block + FC training\n",
    "\n",
    "Let's see what ACC we could obtain if we train the last 2 Conv blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00060: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "11 0.001 0.9 200 2 0.6931447878479957 0.6931476593017578 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "FineTunningVGG(200, 2, 0.001,  0.9, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00095: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0001 0.8 200 2 0.04930473282502135 0.7669441649690271 0.975 0.6\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00114: early stopping\n",
      "Training time: 1.2 mins ---\n",
      "11 0.0001 0.8 200 5 0.08175505104009062 0.792159415781498 0.9625000022351742 0.6500000134110451\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00111: early stopping\n",
      "Training time: 1.7 mins ---\n",
      "11 0.0001 0.9 200 2 0.3877230196038909 0.8754680104553699 0.85 0.7\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00095: early stopping\n",
      "Training time: 1.0 mins ---\n",
      "11 0.0001 0.9 200 5 0.0306460354840965 0.4901685491204262 0.9750000014901161 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00054: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "11 0.0005 0.8 200 2 0.269014053652063 0.5410878553986549 0.925 0.75\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00064: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "11 0.0005 0.8 200 5 0.11292863066773862 0.4694807417690754 0.9625000022351742 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00057: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "11 0.0005 0.9 200 2 0.6930806085467338 0.6931477606296539 0.5125 0.5\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00125: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 200 5 0.2282433467953524 0.5949657279998064 0.9250000044703484 0.800000011920929\n",
      "Total time: 9.8 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [11] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-4, 5e-4]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [200]\n",
    "batch_sizeValues = [2, 5]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of 80% is not better, so let's try a more flexible training by adding an extra FC layer (no weights loading!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunningVGG2FC(epochs, batch_size, learning, mom, freezeLayers, drop, neurons):\n",
    "    # Fine tuning function using VGG16 and our weights for the FC layer (top model)\n",
    "    # 2 FC: 1 = 256 (as orginal), 2 = variable\n",
    "    \n",
    "    # Set seeeds for reproductibility\n",
    "    #seed(1)            # numpy seed\n",
    "    #set_random_seed(2) # tensorflow seed\n",
    "    \n",
    "    # Build the VGG16 block using our input size 150, 150, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "    # Build a classifier model to put on top of the convolutional model (FC layer / top model)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(drop))\n",
    "    top_model.add(Dense(neurons, activation='relu'))\n",
    "    top_model.add(Dropout(drop))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Is necessary to start with a fully-trained classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    \n",
    "    # Load the previous calculated weight for the top model\n",
    "    # top_model.load_weights(top_model_weights_path) # NO weights loading\n",
    "\n",
    "    # Add the model on top of the convolutional base\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # Set the first 'freezeLayers' layers to non-trainable (weights will not be updated)\n",
    "    # This number depends on the blocks to freeze: for the last Conv block freeze 15 layers,\n",
    "    # to freeze 2 last conv blocks freeze only 11 layers.\n",
    "    for layer in model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizers.SGD(lr=learning, momentum=mom), # lr=1e-4, momentum=0.9\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1. / 255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 90)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Generate training and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use earlystopping:\n",
    "    callbacks=[EarlyStopping(\n",
    "                            monitor='val_acc', \n",
    "                            patience=100, # very patient!\n",
    "                            mode='max',\n",
    "                            verbose=1),\n",
    "                ModelCheckpoint(earlystoping_path[:-3]+'_e'+str(epochs)+'b'+str(batch_size)+'l'+str(learning)+'m'+str(mom)+'f'+str(freezeLayers)+'d'+str(drop)+'n'+str(neurons)+'.h5',\n",
    "                            monitor='val_acc', \n",
    "                            save_best_only=True, \n",
    "                            mode='max',\n",
    "                            verbose=0)]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        workers=7, # 7 cores of the CPU!\n",
    "        verbose = 0,\n",
    "        callbacks=callbacks) # remove this param if you dont need early stopping\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training time: %0.1f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "    # Evaluate final test loss and accuracy scores\n",
    "    scoresVal = model.evaluate_generator(validation_generator, nb_validation_samples//batch_size, workers=7)\n",
    "    scoresTr  = model.evaluate_generator(train_generator, nb_train_samples//batch_size, workers=7)\n",
    "    # Print the results\n",
    "    print(freezeLayers, learning, mom, epochs, batch_size, drop, neurons, scoresTr[0], scoresVal[0], scoresTr[1], scoresVal[1])\n",
    "\n",
    "    # clean some memory\n",
    "    del base_model\n",
    "    del top_model\n",
    "    del model\n",
    "\n",
    "    del train_datagen\n",
    "    del train_generator\n",
    "    del validation_generator\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00140: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 128 0.012667301005421905 0.8595507107675076 1.0 0.6500000134110451\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00334: early stopping\n",
      "Training time: 3.7 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 256 0.00014107400495788625 0.5074687451124191 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00166: early stopping\n",
      "Training time: 1.9 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 512 0.0030618831838182814 0.630945498123765 1.0 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00122: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 1024 0.0073986175393656595 0.7015315694734454 1.0 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00194: early stopping\n",
      "Training time: 2.2 mins ---\n",
      "11 0.0005 0.9 500 5 0.2 128 0.39806990697979927 0.8742059022188187 0.8125000111758709 0.600000012665987\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00215: early stopping\n",
      "Training time: 2.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.2 256 0.005789140535853221 0.8735665641725063 1.0 0.7500000074505806\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00191: early stopping\n",
      "Training time: 2.2 mins ---\n",
      "11 0.0005 0.9 500 5 0.2 512 0.0005136355101740264 1.068858275131788 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00152: early stopping\n",
      "Training time: 1.8 mins ---\n",
      "11 0.0005 0.9 500 5 0.2 1024 0.014618051049183123 0.6186872646212578 1.0 0.7500000074505806\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00160: early stopping\n",
      "Training time: 1.9 mins ---\n",
      "11 0.0005 0.9 500 5 0.3 128 0.02042551444083074 1.0601404532790184 1.0 0.7000000178813934\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00122: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.3 256 0.16316962195560336 0.5976318269968033 0.9500000029802322 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00125: early stopping\n",
      "Training time: 1.5 mins ---\n",
      "11 0.0005 0.9 500 5 0.3 512 0.023149129141529556 0.6082292422652245 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00127: early stopping\n",
      "Training time: 1.5 mins ---\n",
      "11 0.0005 0.9 500 5 0.3 1024 0.051267167247715406 0.7833060920238495 0.9875000007450581 0.7000000178813934\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00181: early stopping\n",
      "Training time: 2.1 mins ---\n",
      "11 0.0005 0.9 500 5 0.4 128 0.07126131138647906 0.6049795672297478 0.9750000014901161 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00184: early stopping\n",
      "Training time: 2.1 mins ---\n",
      "11 0.0005 0.9 500 5 0.4 256 0.09429500678379554 0.628852779045701 0.9500000029802322 0.8500000089406967\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00117: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.4 512 0.1749166646914091 0.7597609236836433 0.9250000044703484 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00194: early stopping\n",
      "Training time: 2.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.4 1024 0.0014252524629227992 0.8847778347553685 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00149: early stopping\n",
      "Training time: 1.8 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 128 0.4302956461906433 0.506069727241993 0.8375000096857548 0.8000000044703484\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00139: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 256 0.33924846770241857 0.5518210977315903 0.8625000081956387 0.6500000134110451\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00105: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 512 0.5953572243452072 0.6364353895187378 0.7000000132247806 0.6000000238418579\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00197: early stopping\n",
      "Training time: 2.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 1024 0.0026548308126166376 1.2069445848464966 1.0 0.600000012665987\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00148: early stopping\n",
      "Training time: 1.8 mins ---\n",
      "11 0.0005 0.9 500 5 0.6 128 0.6943324618041515 0.6943324506282806 0.500000013038516 0.5000000111758709\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00257: early stopping\n",
      "Training time: 3.1 mins ---\n",
      "11 0.0005 0.9 500 5 0.6 256 0.5042204651981592 0.62815061211586 0.8125000093132257 0.600000012665987\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00248: early stopping\n",
      "Training time: 2.9 mins ---\n",
      "11 0.0005 0.9 500 5 0.6 512 0.01583464612485841 0.9560783789493144 1.0 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00221: early stopping\n",
      "Training time: 2.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.6 1024 0.0657061710517155 0.6702374964952469 0.9875000007450581 0.7500000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00103: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.7 128 0.6931376233696938 0.6931000649929047 0.5125000132247806 0.5500000156462193\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00138: early stopping\n",
      "Training time: 1.7 mins ---\n",
      "11 0.0005 0.9 500 5 0.7 256 0.6931475400924683 0.6931475549936295 0.5000000121071935 0.5000000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00132: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.7 512 0.6583734527230263 0.63841313123703 0.5875000115483999 0.5500000156462193\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00107: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.7 1024 0.6918778382241726 0.692557230591774 0.6625000135973096 0.5000000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00116: early stopping\n",
      "Training time: 1.5 mins ---\n",
      "11 0.0005 0.9 500 5 0.8 128 0.6931534856557846 0.6931534856557846 0.5000000149011612 0.5000000186264515\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00113: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.8 256 0.6931476183235645 0.6931476294994354 0.500000013038516 0.5000000186264515\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00105: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.8 512 0.6931473016738892 0.693147286772728 0.5000000149011612 0.5000000111758709\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00182: early stopping\n",
      "Training time: 2.2 mins ---\n",
      "11 0.0005 0.9 500 5 0.8 1024 0.6931473016738892 0.6931473016738892 0.5000000121071935 0.5000000111758709\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00108: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 128 0.693159606307745 0.6931596249341965 0.5000000102445483 0.5000000111758709\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00129: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 256 0.6931614987552166 0.6931614726781845 0.5000000074505806 0.5000000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00101: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 512 0.6931487210094929 0.6931487172842026 0.500000013038516 0.5000000111758709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00102: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 1024 0.69315180554986 0.6931518018245697 0.5000000121071935 0.5000000149011612\n"
     ]
    }
   ],
   "source": [
    "# FineTunningVGG2FC(epochs, batch_size, learning, mom, freezeLayers, drop, neurons)\n",
    "# 2 FC, 1 = 256, 2 = variable\n",
    "# 11 0.0005 0.9 200 5 0.2282433467953524 0.5949657279998064 0.9250000044703484 0.800000011920929\n",
    "for idrop in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 , 0.9]:\n",
    "    for ineurons in [128, 256, 512, 1024]:\n",
    "        FineTunningVGG2FC(500, 5, 0.0005,  0.9, 11, idrop, ineurons)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results for 2 FC layers have been obtained for:\n",
    "11 0.0005 0.9 500 5 0.4 256 0.09429500678379554 0.628852779045701 0.9500000029802322 0.8500000089406967\n",
    "\n",
    "Let's try only 1 FC layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunningVGG1FC(epochs, batch_size, learning, mom, freezeLayers, drop, neurons):\n",
    "    # Fine tuning function using VGG16 and our weights for the FC layer (top model)\n",
    "    # 1 variable FC\n",
    "    \n",
    "    # Set seeeds for reproductibility\n",
    "    #seed(1)            # numpy seed\n",
    "    #set_random_seed(2) # tensorflow seed\n",
    "    \n",
    "    # Build the VGG16 block using our input size 150, 150, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "    # Build a classifier model to put on top of the convolutional model (FC layer / top model)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "\n",
    "    top_model.add(Dense(neurons, activation='relu'))\n",
    "    top_model.add(Dropout(drop))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Is necessary to start with a fully-trained classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    \n",
    "    # Load the previous calculated weight for the top model\n",
    "    # top_model.load_weights(top_model_weights_path) # NO weights loading\n",
    "\n",
    "    # Add the model on top of the convolutional base\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # Set the first 'freezeLayers' layers to non-trainable (weights will not be updated)\n",
    "    # This number depends on the blocks to freeze: for the last Conv block freeze 15 layers,\n",
    "    # to freeze 2 last conv blocks freeze only 11 layers.\n",
    "    for layer in model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizers.SGD(lr=learning, momentum=mom), # lr=1e-4, momentum=0.9\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1. / 255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 90)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Generate training and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use earlystopping:\n",
    "    callbacks=[EarlyStopping(\n",
    "                            monitor='val_acc', \n",
    "                            patience=100, # very patient!\n",
    "                            mode='max',\n",
    "                            verbose=1),\n",
    "                ModelCheckpoint(earlystoping_path[:-3]+'_e'+str(epochs)+'b'+str(batch_size)+'l'+str(learning)+'m'+str(mom)+'f'+str(freezeLayers)+'d'+str(drop)+'n'+str(neurons)+'.h5',\n",
    "                            monitor='val_acc', \n",
    "                            save_best_only=True, \n",
    "                            mode='max',\n",
    "                            verbose=0)]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        workers=7, # 7 cores of the CPU!\n",
    "        verbose = 0,\n",
    "        callbacks=callbacks) # remove this param if you dont need early stopping\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training time: %0.1f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "    # Evaluate final test loss and accuracy scores\n",
    "    scoresVal = model.evaluate_generator(validation_generator, nb_validation_samples//batch_size, workers=7)\n",
    "    scoresTr  = model.evaluate_generator(train_generator, nb_train_samples//batch_size, workers=7)\n",
    "    # Print the results\n",
    "    print(freezeLayers, learning, mom, epochs, batch_size, drop, neurons, scoresTr[0], scoresVal[0], scoresTr[1], scoresVal[1])\n",
    "\n",
    "    # clean some memory\n",
    "    del base_model\n",
    "    del top_model\n",
    "    del model\n",
    "\n",
    "    del train_datagen\n",
    "    del train_generator\n",
    "    del validation_generator\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00125: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 128 0.05436937647755258 0.46945618093013763 0.9875000007450581 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00217: early stopping\n",
      "Training time: 2.4 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 256 0.013837655367296975 1.8047126233577728 1.0 0.6000000163912773\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00116: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 512 0.3622851693071425 0.5248122736811638 0.8250000104308128 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00211: early stopping\n",
      "Training time: 2.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.1 1024 0.0007533760493174668 0.9735153184155934 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00158: early stopping\n",
      "Training time: 1.7 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 128 0.017597826605197042 0.6242238208651543 1.0 0.800000011920929\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00120: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 256 0.6931734979152679 0.6932176500558853 0.5000000121071935 0.5000000037252903\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00145: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 512 0.6931098960340023 0.6931558549404144 0.5000000121071935 0.5000000186264515\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00139: early stopping\n",
      "Training time: 1.6 mins ---\n",
      "11 0.0005 0.9 500 5 0.5 1024 0.256374983349815 0.4465976972132921 0.9250000044703484 0.7500000074505806\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00104: early stopping\n",
      "Training time: 1.1 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 128 0.6931594908237457 0.6931473314762115 0.5000000149011612 0.5000000149011612\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00115: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 256 0.6931479386985302 0.6931479275226593 0.5000000111758709 0.5000000186264515\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00102: early stopping\n",
      "Training time: 1.2 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 512 0.6931472644209862 0.6931472569704056 0.5000000111758709 0.5000000111758709\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 00116: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0005 0.9 500 5 0.9 1024 0.6931474208831787 0.6931474357843399 0.5000000121071935 0.5000000074505806\n"
     ]
    }
   ],
   "source": [
    "# if we use Adam => 0.5 ACC!\n",
    "for idrop in [0.1, 0.5, 0.9]:\n",
    "    for ineurons in [128, 256, 512, 1024]:\n",
    "        FineTunningVGG1FC(500, 5, 0.0005,  0.9, 11, idrop, ineurons) # 1 FC no weight loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results for 1 FC have been obtained for:\n",
    "11 0.0005 0.9 500 5 0.1 512 0.3622851693071425 0.5248122736811638 0.8250000104308128 0.800000011920929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* If you apply the fine tuning for the last conv block of VGG16 + FC (top model), you can obtain an accuracy of `75%`. This values is no better compare with the small CNN and the Transfer Learning results (`over 80%`).\n",
    "* But if you train the 2 last Conv block of VGG16 + FC (top model), you can obtain test accuracy of `85%`!\n",
    "* The search space was limited and possible additional hyperparameter combinations should be tested including drop rate, optimizer or the base model (not only VGG16, it could be Inception, RNN, etc.).\n",
    "\n",
    "If you need a classifier to detect Spanish political affinity using people portraits, you should try the VGG16 fine tuning for at least 85% of accuracy.\n",
    "\n",
    "Have fun with DL!\n",
    "@muntisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "I gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research ([https://developer.nvidia.com/academic_gpu_seeding](https://developer.nvidia.com/academic_gpu_seeding))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
